{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Linear and Nonlinear Data Generating Process benchmarking",
   "id": "4b910fd3ff24a2e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Data Generating Process (DGP)",
   "id": "6c7c7c3e95e974a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let $i=1,\\dots,n$. Draw confounders:\n",
    "\n",
    "$$\n",
    "\\text{tenure}_i \\sim \\mathcal N(24,\\ 12^2)\n",
    "$$\n",
    "$$\n",
    "\\text{sessions}_i \\sim \\mathcal N(5,\\ 2^2)\n",
    "$$\n",
    "$$\n",
    "\\text{spend}_i \\sim \\mathrm{Unif}(0,200)\n",
    "$$\n",
    "$$\n",
    "\\text{prem}_i \\sim \\mathrm{Bernoulli}(0.25)\n",
    "$$\n",
    "$$\n",
    "\\text{urban}_i \\sim \\mathrm{Bernoulli}(0.60)\n",
    "$$\n",
    "Stack them as\n",
    "\n",
    "$$\n",
    "X_i := \\big[\\ \\text{tenure}_i,\\ \\text{sessions}_i,\\ \\text{spend}_i,\\ \\text{prem}_i,\\ \\text{urban}_i\\ \\big]^\\top \\in \\mathbb{R}^5\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Treatment model\n",
    "\n",
    "$$\n",
    "m(x) \\equiv \\Pr(D=1\\mid X=x) = \\sigma\\big(\\alpha_d + x^\\top \\beta_t\\big),\n",
    "\\qquad\n",
    "\\sigma(z)=\\frac{1}{1+e^{-z}},\n",
    "$$\n",
    "\n",
    "with $\\alpha_d$ calibrated (by bisection) so that $\\mathbb{E}[D]\\approx 0.20$, and\n",
    "\n",
    "$$\n",
    "\\beta_t^\\top = \\big[, 0.08,\\ 0.12,\\ 0.004,\\ 0.25,\\ 0.10 \\big]\n",
    "$$\n",
    "\n",
    "Then\n",
    "$$D_i \\mid X_i \\sim \\mathrm{Bernoulli}\\big(m(X_i)\\big)$$\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome model\n",
    "\n",
    "$$\n",
    "Y_i = \\alpha_y + X_i^\\top \\beta_y + \\Theta D_i + \\varepsilon_i,\n",
    "\\qquad\n",
    "\\varepsilon_i \\sim \\mathcal N(0,\\sigma_y^2),\n",
    "$$\n",
    "\n",
    "with $\\alpha_y=0,\\ \\sigma_y=1,\\ \\Theta=0.80$, and\n",
    "\n",
    "$$\n",
    "\\beta_y^\\top = \\big[0.05,\\ 0.60,\\ 0.005,\\ 0.80,\\ 0.20 \\big]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Oracle nuisances (IRM) and CATE\n",
    "\n",
    "$$\n",
    "m(x) = \\sigma\\!\\big(\\alpha_d + x^\\top \\beta_t\\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_0(x) = \\mathbb{E}[Y \\mid X=x, D=0]\n",
    "       = \\alpha_y + x^\\top \\beta_y\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_1(x) = \\mathbb{E}[Y \\mid X=x, D=1]\n",
    "       = \\alpha_y + x^\\top \\beta_y + \\Theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{CATE}(x) = g_1(x) - g_0(x)\n",
    "                 = \\Theta \\quad \\text{(constant)}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Targets\n",
    "\n",
    "$$\n",
    "\\Theta_{\\text{ATE}}\n",
    "= \\mathbb{E}\\big[Y(1)-Y(0)\\big]\n",
    "= \\Theta,\n",
    "\\qquad\n",
    "\\Theta_{\\text{ATTE}}\n",
    "= \\mathbb{E}\\big[Y(1)-Y(0)\\mid D=1\\big]\n",
    "= \\Theta.\n",
    "$$\n",
    "\n",
    "So under this constant-effect DGP:\n",
    "\n",
    "$$\n",
    "\\Theta_{\\text{ATE}} = \\Theta_{\\text{ATTE}} = 0.80.\n",
    "$$\n",
    "\n",
    "---"
   ],
   "id": "15197ab988fb731e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Let's generate the Data",
   "id": "519e27e45fe8b5e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:14:57.277724Z",
     "start_time": "2025-10-04T10:14:56.898673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from causalis.data_contracts import CausalDatasetGenerator\n",
    "\n",
    "confounder_specs: List[Dict[str, Any]] = [\n",
    "    {\"name\": \"tenure_months\",     \"dist\": \"normal\",   \"mu\": 24, \"sd\": 12},\n",
    "    {\"name\": \"avg_sessions_week\", \"dist\": \"normal\",   \"mu\": 5,  \"sd\": 2},\n",
    "    {\"name\": \"spend_last_month\",  \"dist\": \"uniform\",  \"a\": 0,   \"b\": 200},\n",
    "    {\"name\": \"premium_user\",      \"dist\": \"bernoulli\",\"p\": 0.25},\n",
    "    {\"name\": \"urban_resident\",    \"dist\": \"bernoulli\",\"p\": 0.60},\n",
    "]\n",
    "\n",
    "# Moderate, sensible effects by column name (linear, well-specified)\n",
    "# Outcome: higher sessions, tenure, spend, premium, urban -> higher Y\n",
    "beta_y_map = {\n",
    "    \"tenure_months\":     0.05,   # ~0.6 SD shift at +1 SD (12 months)\n",
    "    \"avg_sessions_week\": 0.60,   # strong engagement signal\n",
    "    \"spend_last_month\":  0.005,  # scale 0..200 => up to ~1 shift\n",
    "    \"premium_user\":      0.80,\n",
    "    \"urban_resident\":    0.20,\n",
    "}\n",
    "\n",
    "# Treatment score: moderate dependence on engagement, spend, premium, urban\n",
    "beta_d_map = {\n",
    "    \"tenure_months\":     0.08,\n",
    "    \"avg_sessions_week\": 0.12,\n",
    "    \"spend_last_month\":  0.004,\n",
    "    \"premium_user\":      0.25,\n",
    "    \"urban_resident\":    0.10,\n",
    "}\n",
    "\n",
    "def expand_beta_from_specs(specs: List[Dict[str, Any]], beta_map: Dict[str, float]) -> np.ndarray:\n",
    "    \"\"\"Create β aligned to the generator's X column order from confounder_specs.\"\"\"\n",
    "    betas = []\n",
    "    for spec in specs:\n",
    "        name = spec.get(\"name\", \"\")\n",
    "        dist = str(spec.get(\"dist\", \"normal\")).lower()\n",
    "        if dist in (\"normal\", \"uniform\", \"bernoulli\"):\n",
    "            betas.append(beta_map.get(name, 0.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dist in this simple setup: {dist}\")\n",
    "    return np.asarray(betas, dtype=float)\n",
    "\n",
    "beta_y = expand_beta_from_specs(confounder_specs, beta_y_map)\n",
    "beta_d = expand_beta_from_specs(confounder_specs, beta_d_map)\n",
    "\n",
    "gen = CausalDatasetGenerator(\n",
    "    theta=0.80,                 # constant treatment effect\n",
    "    tau=None,                   # use theta\n",
    "    beta_y=beta_y,              # linear connection between X and Y\n",
    "    beta_d=beta_d,              # linear connection between X and D\n",
    "    g_y=None, g_d=None,         # no nonlinearities\n",
    "    alpha_y=0.0,                # no intercept\n",
    "    alpha_d=0.0,                # no intercept\n",
    "    sigma_y=1.0,                # noise of y\n",
    "    outcome_type=\"continuous\",  # Gaussian Y\n",
    "    confounder_specs=confounder_specs,\n",
    "    u_strength_d=0.0,           # strength of latent confounder influence on treatment\n",
    "    u_strength_y=0.0,           # strength of latent confounder influence on outcome\n",
    "    propensity_sharpness=1.0,   # increase to make overlap harder\n",
    "    target_d_rate=0.20,         # rate of treatment assignment\n",
    "    seed=123                    # random seed for reproducibility\n",
    ")\n",
    "\n",
    "n = 10_000                      # Number of observations\n",
    "df = gen.generate(n)\n",
    "\n",
    "print(\"Treatment share ≈\", df[\"d\"].mean())\n",
    "true_ate = float(df[\"cate\"].mean())\n",
    "print(f\"Ground-truth ATE from the DGP: {true_ate:.3f}\")\n",
    "# Ground-truth ATT (on the natural scale): E[tau(X) | T=1] = mean CATE among the treated\n",
    "true_att = float(df.loc[df[\"d\"] == 1, \"cate\"].mean())\n",
    "print(f\"Ground-truth ATT from the DGP: {true_att:.3f}\")"
   ],
   "id": "441122f7a58f4578",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment share ≈ 0.2052\n",
      "Ground-truth ATE from the DGP: 0.800\n",
      "Ground-truth ATT from the DGP: 0.800\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wrap it in CausalData Object",
   "id": "25078b9f17a0ca2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:14:57.296347Z",
     "start_time": "2025-10-04T10:14:57.286022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from causalis.data_contracts import CausalData\n",
    "\n",
    "causal_data = CausalData(\n",
    "    df=df,\n",
    "    treatment=\"d\",\n",
    "    outcome=\"y\",\n",
    "    confounders=[\"tenure_months\",\n",
    "                 \"avg_sessions_week\",\n",
    "                 \"spend_last_month\",\n",
    "                 \"premium_user\",\n",
    "                 \"premium_user\",\n",
    "                 \"urban_resident\"]\n",
    ")\n",
    "\n",
    "causal_data.df.head()"
   ],
   "id": "efc74e981147010c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          y    d  tenure_months  avg_sessions_week  spend_last_month  \\\n",
       "0  1.903910  0.0      12.130544           4.056687        181.570607   \n",
       "1  3.388144  0.0      19.586560           1.671561        182.793598   \n",
       "2  8.456512  1.0      39.455103           5.452889        125.185708   \n",
       "3  5.535970  1.0      26.327693           5.051629          4.932905   \n",
       "4  4.965140  1.0      35.042771           4.933996         23.577407   \n",
       "\n",
       "   premium_user  urban_resident  \n",
       "0           0.0             0.0  \n",
       "1           0.0             0.0  \n",
       "2           1.0             1.0  \n",
       "3           0.0             1.0  \n",
       "4           0.0             0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>avg_sessions_week</th>\n",
       "      <th>spend_last_month</th>\n",
       "      <th>premium_user</th>\n",
       "      <th>urban_resident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.903910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.130544</td>\n",
       "      <td>4.056687</td>\n",
       "      <td>181.570607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.388144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.586560</td>\n",
       "      <td>1.671561</td>\n",
       "      <td>182.793598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.456512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.455103</td>\n",
       "      <td>5.452889</td>\n",
       "      <td>125.185708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.535970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.327693</td>\n",
       "      <td>5.051629</td>\n",
       "      <td>4.932905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.965140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.042771</td>\n",
       "      <td>4.933996</td>\n",
       "      <td>23.577407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Estimate ATE and ATTE",
   "id": "d9f24be535324856"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:06.379931Z",
     "start_time": "2025-10-04T10:14:57.314859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from causalis.scenarios.unconfoundedness.ate import dml_ate\n",
    "\n",
    "# Estimate Average Treatment Effect (ATE)\n",
    "ate_result = dml_ate(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ],
   "id": "8a00d8ee46727429",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:06.423692Z",
     "start_time": "2025-10-04T10:15:06.421720Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Real ATE = 0.8 VS Estimated = {ate_result.get('coefficient')} in {ate_result.get('confidence_interval')}\")",
   "id": "4922ddeee71fc7ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real ATE = 0.8 VS Estimated = 0.7506313322797796 in (0.6668061755942251, 0.8344564889653342)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:14.564801Z",
     "start_time": "2025-10-04T10:15:06.428729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from causalis.scenarios.unconfoundedness.atte import dml_atte\n",
    "\n",
    "# Estimate Average Treatment Effect on Treatment (ATTE)\n",
    "atte_result = dml_atte(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ],
   "id": "e0a6f5e4d57ea075",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:14.576099Z",
     "start_time": "2025-10-04T10:15:14.574549Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Real ATTE = 0.8 VS Estimated = {atte_result.get('coefficient')} in {atte_result.get('confidence_interval')}\")",
   "id": "7577a33e87f133cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real ATTE = 0.8 VS Estimated = 0.8238669785039335 in (0.7558326760362799, 0.8919012809715872)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The estimated ATE and ATTE are close to the ground truth values. But we got wide confidence_intervals.\n",
    "Adding more data makes the intervals narrower. You can try it when changes the n in GDP"
   ],
   "id": "273ae669024dc29f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Nonlinear Data Generating Process (DGP)",
   "id": "cf6c03d1555a2cd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let $i=1,\\dots,n$. Draw confounders:\n",
    "\n",
    "$$\n",
    "\\text{tenure}_i \\sim \\mathcal N(24,\\ 12^2)\n",
    "$$\n",
    "$$\n",
    "\\text{sessions}_i \\sim \\mathcal N(5,\\ 2^2)\n",
    "$$\n",
    "$$\n",
    "\\text{spend}_i \\sim \\mathrm{Unif}(0,200)\n",
    "$$\n",
    "$$\n",
    "\\text{prem}_i \\sim \\mathrm{Bernoulli}(0.25)\n",
    "$$\n",
    "$$\n",
    "\\text{urban}_i \\sim \\mathrm{Bernoulli}(0.60)\n",
    "$$\n",
    "\n",
    "Stack them as\n",
    "\n",
    "$$\n",
    "X_i := \\big[\\ \\text{tenure}_i,\\ \\text{sessions}_i,\\ \\text{spend}_i,\\ \\text{prem}_i,\\ \\text{urban}_i\\ \\big]^\\top \\in \\mathbb{R}^5\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Treatment model\n",
    "\n",
    "Define\n",
    "$$\n",
    "m(x) \\equiv \\Pr(D=1\\mid X=x) = \\sigma\\big(\\alpha_d + g_d(x)\\big),\n",
    "\\qquad\n",
    "\\sigma(z)=\\frac{1}{1+e^{-z}},\n",
    "$$\n",
    "\n",
    "with $\\alpha_d$ calibrated (by bisection) so that $\\mathbb{E}[D]\\approx 0.20$.\n",
    "\n",
    "The nonlinear score includes **alignment with the treatment effect** $\\tau(x)$:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "g_d(x) &= 1.10\\tanh\\big(0.06(\\text{spend}-100)\\big)\n",
    "+ 1.00\\sigma\\big(0.60(\\text{sessions}-5)\\big)\n",
    "+ 0.50\\log\\big(1+\\text{tenure}\\big)\n",
    "+ 0.50\\text{prem}\n",
    "+ 0.25\\text{urban}\n",
    "+ 0.90\\text{prem}\\cdot\\mathbb{\\text{spend}>120}\n",
    "+ 0.30\\text{urban}\\cdot\\mathbb{\\text{tenure}<12}\n",
    "+0.80\\tau(x)\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "where $z_+ = \\max(z,0)$ and $\\mathbb{1}{\\cdot}$ is the indicator.\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "D_i \\mid X_i \\sim \\mathrm{Bernoulli}\\big(m(X_i)\\big)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome model\n",
    "\n",
    "$$\n",
    "Y_i = \\alpha_y + g_y(X_i) + D_i\\tau(X_i) + \\varepsilon_i,\n",
    "\\qquad\n",
    "\\varepsilon_i \\sim \\mathcal N(0,\\sigma_y^2),\n",
    "$$\n",
    "\n",
    "with $\\alpha_y=0,\\ \\sigma_y=1$.\n",
    "\n",
    "The baseline outcome component is nonlinear:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "g_y(x) &= 0.70\\tanh\\big(0.03(\\text{spend}-80)\\big)\n",
    "+ 0.50\\sqrt{\\text{sessions}}\n",
    "+ 0.40\\log\\big(1+\\text{tenure}\\big)\n",
    "+ 0.30\\text{prem}\n",
    "+ 0.10\\text{urban}\n",
    "- 0.10\\mathbb{\\text{spend}<20}\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "The heterogeneous treatment effect (CATE) is\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "\\tau(x) &= 0.40\n",
    "+ 0.60\\sigma\\big(-0.40(\\text{sessions}-5)\\big)\n",
    "+ 2.00\\text{prem}\\cdot\\mathbb{\\text{spend}>120} \\\n",
    "+ 0.10\\text{urban}\\cdot\\mathbb{\\text{tenure}<12}\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Oracle nuisances (IRM) and CATE\n",
    "\n",
    "$$\n",
    "m(x) = \\sigma\\big(\\alpha_d + g_d(x)\\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_0(x) = \\mathbb{E}[Y \\mid X=x, D=0]\n",
    "= \\alpha_y + g_y(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_1(x) = \\mathbb{E}[Y \\mid X=x, D=1]\n",
    "= \\alpha_y + g_y(x) + \\tau(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{CATE}(x) = g_1(x) - g_0(x)\n",
    "= \\tau(x)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Targets\n",
    "\n",
    "$$\n",
    "\\Theta_{\\text{ATE}}\n",
    "= \\mathbb{E}\\big[\\tau(X)\\big],\n",
    "\\qquad\n",
    "\\Theta_{\\text{ATTE}}\n",
    "= \\mathbb{E}\\big[\\tau(X)\\mid D=1\\big].\n",
    "$$\n"
   ],
   "id": "e08a2121cdec0dee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:14.600542Z",
     "start_time": "2025-10-04T10:15:14.578481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from causalis.data_contracts import CausalDatasetGenerator\n",
    "\n",
    "# 1) confounders\n",
    "confounder_specs: List[Dict[str, Any]] = [\n",
    "    {\"name\": \"tenure_months\",     \"dist\": \"normal\",    \"mu\": 24, \"sd\": 12},\n",
    "    {\"name\": \"avg_sessions_week\", \"dist\": \"normal\",    \"mu\": 5,  \"sd\": 2},\n",
    "    {\"name\": \"spend_last_month\",  \"dist\": \"uniform\",   \"a\": 0,   \"b\": 200},\n",
    "    {\"name\": \"premium_user\",      \"dist\": \"bernoulli\", \"p\": 0.25},\n",
    "    {\"name\": \"urban_resident\",    \"dist\": \"bernoulli\", \"p\": 0.60},\n",
    "]\n",
    "\n",
    "# 2) Feature index map\n",
    "def feature_indices_from_specs(specs: List[Dict[str, Any]]) -> Dict[str, Tuple[int, ...]]:\n",
    "    idx, out = 0, {}\n",
    "    for spec in specs:\n",
    "        name = spec.get(\"name\", \"\")\n",
    "        dist = str(spec.get(\"dist\",\"normal\")).lower()\n",
    "        if dist in (\"normal\",\"uniform\",\"bernoulli\"):\n",
    "            out[name] = (idx,); idx += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dist: {dist}\")\n",
    "    return out\n",
    "\n",
    "feat = feature_indices_from_specs(confounder_specs)\n",
    "def col(X, key): return X[:, feat[key][0]]\n",
    "def _log1p_pos(x): return np.log1p(np.clip(x, 0.0, None))\n",
    "def _sqrt_pos(x):  return np.sqrt(np.clip(x, 0.0, None))\n",
    "def _ind(cond):    return cond.astype(float)\n",
    "def _sigmoid(z):   return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# 3) g_d(x) -   nonlinear connection between X and D\n",
    "def g_d(X: np.ndarray) -> np.ndarray:\n",
    "    tenure = col(X, \"tenure_months\")\n",
    "    sess   = col(X, \"avg_sessions_week\")\n",
    "    spend  = col(X, \"spend_last_month\")\n",
    "    prem   = col(X, \"premium_user\")\n",
    "    urban  = col(X, \"urban_resident\")\n",
    "    tau_align = tau_func(X)                                       # explicit alignment\n",
    "    return (\n",
    "        1.10 * np.tanh(0.06*(spend - 100.0))\n",
    "      + 1.00 * _sigmoid(0.60*(sess - 5.0))\n",
    "      + 0.50 * _log1p_pos(tenure)\n",
    "      + 0.50 * prem\n",
    "      + 0.25 * urban\n",
    "      + 0.90 * prem * _ind(spend > 120.0)\n",
    "      + 0.30 * urban * _ind(tenure < 12.0)\n",
    "      + 0.80 * tau_align                                         # direct alignment term (λ)\n",
    "    )\n",
    "\n",
    "\n",
    "# 4) g_y(x)  -   nonlinear connection between X and Y\n",
    "def g_y(X: np.ndarray) -> np.ndarray:\n",
    "    tenure = col(X, \"tenure_months\")\n",
    "    sess   = col(X, \"avg_sessions_week\")\n",
    "    spend  = col(X, \"spend_last_month\")\n",
    "    prem   = col(X, \"premium_user\")\n",
    "    urban  = col(X, \"urban_resident\")\n",
    "    return (\n",
    "        0.70 * np.tanh(0.03*(spend - 80.0))\n",
    "      + 0.50 * _sqrt_pos(sess)\n",
    "      + 0.40 * _log1p_pos(tenure)\n",
    "      + 0.30 * prem\n",
    "      + 0.10 * urban\n",
    "      - 0.10 * _ind(spend < 20.0)\n",
    "    )\n",
    "\n",
    "# 5) tau(x)  — nonlinear effect function (CATE)\n",
    "def tau_func(X: np.ndarray) -> np.ndarray:\n",
    "    tenure = col(X, \"tenure_months\")\n",
    "    sess   = col(X, \"avg_sessions_week\")\n",
    "    spend  = col(X, \"spend_last_month\")\n",
    "    prem   = col(X, \"premium_user\")\n",
    "    urban  = col(X, \"urban_resident\")\n",
    "    return (\n",
    "        0.40\n",
    "      + 0.60 * (1.0 / (1.0 + np.exp(-0.40*(sess - 5.0))))  # sigmoid\n",
    "      + 2 * prem * _ind(spend > 120.0)\n",
    "      + 0.10 * urban * _ind(tenure < 12.0)\n",
    "    )\n",
    "\n",
    "# 6) Generator — continuous outcome\n",
    "gen = CausalDatasetGenerator(\n",
    "    theta=0.0,                 # ignored; we pass tau\n",
    "    tau=tau_func,              # nonlinear effect\n",
    "    beta_y=None, beta_d=None,  # use nonlinear g_* only\n",
    "    g_y=g_y, g_d=g_d,          # nonlinear functions\n",
    "    alpha_y=0.0,               # baseline mean level, intercept\n",
    "    alpha_d=0.0,               # will be calibrated to target_d_rate\n",
    "    sigma_y=1.0,               # noise std for Y\n",
    "    outcome_type=\"continuous\", # outcome distribution\n",
    "    confounder_specs=confounder_specs,\n",
    "    target_d_rate=0.20,        # 20% will be treated\n",
    "    u_strength_d=0.0,          # strength of latent confounder influence on treatment\n",
    "    u_strength_y=0.0,          # strength of latent confounder influence on outcome\n",
    "    propensity_sharpness=1,    # increase to make overlap harder\n",
    "    seed=123                   # random seed for reproducibility\n",
    ")\n",
    "\n",
    "# 7) Generate\n",
    "n = 10_000                     # Number of observations\n",
    "df = gen.generate(n)\n",
    "\n",
    "\n",
    "print(\"Treatment share ≈\", df[\"d\"].mean())\n",
    "true_ate = float(df[\"cate\"].mean())\n",
    "print(f\"Ground-truth ATE from the DGP: {true_ate:.3f}\")\n",
    "# Ground-truth ATT (on the natural scale): E[tau(X) | T=1] = mean CATE among the treated\n",
    "true_att = float(df.loc[df[\"d\"] == 1, \"cate\"].mean())\n",
    "print(f\"Ground-truth ATT from the DGP: {true_att:.3f}\")"
   ],
   "id": "a2bb40eefd8a61bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment share ≈ 0.2036\n",
      "Ground-truth ATE from the DGP: 0.913\n",
      "Ground-truth ATT from the DGP: 1.567\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:14.610751Z",
     "start_time": "2025-10-04T10:15:14.602555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from causalis.data_contracts import CausalData\n",
    "\n",
    "causal_data = CausalData(\n",
    "    df=df,\n",
    "    treatment=\"d\",\n",
    "    outcome=\"y\",\n",
    "    confounders=[\"tenure_months\",\n",
    "                 \"avg_sessions_week\",\n",
    "                 \"spend_last_month\",\n",
    "                 \"premium_user\",\n",
    "                 \"urban_resident\"]\n",
    ")\n",
    "\n",
    "causal_data.df.head()"
   ],
   "id": "7dc325e362aa0337",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          y    d  tenure_months  avg_sessions_week  spend_last_month  \\\n",
       "0  0.689404  0.0      12.130544           4.056687        181.570607   \n",
       "1  3.045282  0.0      19.586560           1.671561        182.793598   \n",
       "2  7.173595  1.0      39.455103           5.452889        125.185708   \n",
       "3  1.926216  0.0      26.327693           5.051629          4.932905   \n",
       "4  1.225088  0.0      35.042771           4.933996         23.577407   \n",
       "\n",
       "   premium_user  urban_resident  \n",
       "0           0.0             0.0  \n",
       "1           0.0             0.0  \n",
       "2           1.0             1.0  \n",
       "3           0.0             1.0  \n",
       "4           0.0             0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>avg_sessions_week</th>\n",
       "      <th>spend_last_month</th>\n",
       "      <th>premium_user</th>\n",
       "      <th>urban_resident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.689404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.130544</td>\n",
       "      <td>4.056687</td>\n",
       "      <td>181.570607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.045282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.586560</td>\n",
       "      <td>1.671561</td>\n",
       "      <td>182.793598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.173595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.455103</td>\n",
       "      <td>5.452889</td>\n",
       "      <td>125.185708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.926216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.327693</td>\n",
       "      <td>5.051629</td>\n",
       "      <td>4.932905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.225088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.042771</td>\n",
       "      <td>4.933996</td>\n",
       "      <td>23.577407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:22.532635Z",
     "start_time": "2025-10-04T10:15:14.627501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from causalis.scenarios.unconfoundedness.ate import dml_ate\n",
    "\n",
    "# Estimate Average Treatment Effect (ATE)\n",
    "ate_result = dml_ate(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ],
   "id": "c1d9af69db63026d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:22.557911Z",
     "start_time": "2025-10-04T10:15:22.556023Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Real ATE = {true_ate:.3f} VS Estimated = {ate_result.get('coefficient')} in {ate_result.get('confidence_interval')}\")",
   "id": "d37eb3f48cb33009",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real ATE = 0.913 VS Estimated = 0.9917276396749556 in (0.869543879249174, 1.1139114001007373)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:30.339984Z",
     "start_time": "2025-10-04T10:15:22.562450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from causalis.scenarios.unconfoundedness.atte import dml_atte\n",
    "\n",
    "# Estimate Average Treatment Effect on Treatment (ATTE)\n",
    "atte_result = dml_atte(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ],
   "id": "29f3b4cd518fb6f8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T10:15:30.351375Z",
     "start_time": "2025-10-04T10:15:30.349624Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Real ATTE = {true_att:.3f} VS Estimated = {atte_result.get('coefficient')} in {atte_result.get('confidence_interval')}\")",
   "id": "3d015d26b21a3168",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real ATTE = 1.567 VS Estimated = 1.6433239376940343 in (1.4972790851652928, 1.7893687902227757)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The estimated ATE and ATTE are close to the ground truth values. But we got wide confidence_intervals.\n",
    "Adding more data makes the intervals narrower. You can try it when changes the n in GDP"
   ],
   "id": "edc992dd6e8e96e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
