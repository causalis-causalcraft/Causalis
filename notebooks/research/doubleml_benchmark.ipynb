{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare Implementation of DML IRM in Causalis and DML IRM in DoubleMl",
   "id": "a897969b70223a34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In Causalis we have `dml_ate_source()` implementation. It calls `dml_irm_obj.fit()` from DoubleML. Let's compare it with Causalis `dml_ate()`",
   "id": "79907429d5b2d770"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using DGP from [Linear and Nonlinear Data Generating Process benchmarking](file:///Users/ioannmartynov/PycharmProjects/Ckit/docs/_build/html/research/dgp_benchmarking.html)",
   "id": "f9aef87798968dc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T18:19:59.608353Z",
     "start_time": "2025-12-25T18:19:59.563598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from causalis.data import CausalDatasetGenerator\n",
    "\n",
    "confounder_specs: List[Dict[str, Any]] = [\n",
    "    {\"name\": \"tenure_months\",     \"dist\": \"normal\",   \"mu\": 24, \"sd\": 12},\n",
    "    {\"name\": \"avg_sessions_week\", \"dist\": \"normal\",   \"mu\": 5,  \"sd\": 2},\n",
    "    {\"name\": \"spend_last_month\",  \"dist\": \"uniform\",  \"a\": 0,   \"b\": 200},\n",
    "    {\"name\": \"premium_user\",      \"dist\": \"bernoulli\",\"p\": 0.25},\n",
    "    {\"name\": \"urban_resident\",    \"dist\": \"bernoulli\",\"p\": 0.60},\n",
    "]\n",
    "\n",
    "# Moderate, sensible effects by column name (linear, well-specified)\n",
    "# Outcome: higher sessions, tenure, spend, premium, urban -> higher Y\n",
    "beta_y_map = {\n",
    "    \"tenure_months\":     0.05,   # ~0.6 SD shift at +1 SD (12 months)\n",
    "    \"avg_sessions_week\": 0.60,   # strong engagement signal\n",
    "    \"spend_last_month\":  0.005,  # scale 0..200 => up to ~1 shift\n",
    "    \"premium_user\":      0.80,\n",
    "    \"urban_resident\":    0.20,\n",
    "}\n",
    "\n",
    "# Treatment score: moderate dependence on engagement, spend, premium, urban\n",
    "beta_d_map = {\n",
    "    \"tenure_months\":     0.08,\n",
    "    \"avg_sessions_week\": 0.12,\n",
    "    \"spend_last_month\":  0.004,\n",
    "    \"premium_user\":      0.25,\n",
    "    \"urban_resident\":    0.10,\n",
    "}\n",
    "\n",
    "def expand_beta_from_specs(specs: List[Dict[str, Any]], beta_map: Dict[str, float]) -> np.ndarray:\n",
    "    \"\"\"Create β aligned to the generator's X column order from confounder_specs.\"\"\"\n",
    "    betas = []\n",
    "    for spec in specs:\n",
    "        name = spec.get(\"name\", \"\")\n",
    "        dist = str(spec.get(\"dist\", \"normal\")).lower()\n",
    "        if dist in (\"normal\", \"uniform\", \"bernoulli\"):\n",
    "            betas.append(beta_map.get(name, 0.0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dist in this simple setup: {dist}\")\n",
    "    return np.asarray(betas, dtype=float)\n",
    "\n",
    "beta_y = expand_beta_from_specs(confounder_specs, beta_y_map)\n",
    "beta_d = expand_beta_from_specs(confounder_specs, beta_d_map)\n",
    "\n",
    "gen = CausalDatasetGenerator(\n",
    "    theta=0.80,                 # constant treatment effect\n",
    "    tau=None,                   # use theta\n",
    "    beta_y=beta_y,              # linear connection between X and Y\n",
    "    beta_d=beta_d,              # linear connection between X and D\n",
    "    g_y=None, g_d=None,         # no nonlinearities\n",
    "    alpha_y=0.0,                # no intercept\n",
    "    alpha_d=0.0,                # no intercept\n",
    "    sigma_y=1.0,                # noise of y\n",
    "    outcome_type=\"continuous\",  # Gaussian Y\n",
    "    confounder_specs=confounder_specs,\n",
    "    u_strength_d=0.0,           # strength of latent confounder influence on treatment\n",
    "    u_strength_y=0.0,           # strength of latent confounder influence on outcome\n",
    "    propensity_sharpness=1.0,   # increase to make overlap harder\n",
    "    target_d_rate=0.20,         # rate of treatment assignment\n",
    "    seed=123                    # random seed for reproducibility\n",
    ")\n",
    "\n",
    "n = 10_000                      # Number of observations\n",
    "df = gen.generate(n)\n",
    "\n",
    "print(\"Treatment share ≈\", df[\"d\"].mean())\n",
    "true_ate = float(df[\"cate\"].mean())\n",
    "print(f\"Ground-truth ATE from the DGP: {true_ate:.3f}\")\n",
    "# Ground-truth ATT (on the natural scale): E[tau(X) | T=1] = mean CATE among the treated\n",
    "true_att = float(df.loc[df[\"d\"] == 1, \"cate\"].mean())\n",
    "print(f\"Ground-truth ATT from the DGP: {true_att:.3f}\")"
   ],
   "id": "7905f2265cf6a298",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment share ≈ 0.2052\n",
      "Ground-truth ATE from the DGP: 0.800\n",
      "Ground-truth ATT from the DGP: 0.800\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from causalis.data import CausalData\n",
    "\n",
    "causal_data = CausalData(\n",
    "    df=df,\n",
    "    treatment=\"d\",\n",
    "    outcome=\"y\",\n",
    "    confounders=[\"tenure_months\",\n",
    "                 \"avg_sessions_week\",\n",
    "                 \"spend_last_month\",\n",
    "                 \"premium_user\",\n",
    "                 \"premium_user\",\n",
    "                 \"urban_resident\"]\n",
    ")\n",
    "\n",
    "causal_data.df.head()"
   ],
   "id": "f74238060f4f474f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ATE",
   "id": "96e970ea78db16a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from causalis.scenarios.unconfoundedness.ate import dml_ate\n",
    "\n",
    "# Estimate Average Treatment Effect (ATE)\n",
    "ate_result_causalis = dml_ate(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ],
   "id": "d98a9d5407f1fee2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from causalis.scenarios.unconfoundedness.ate import dml_ate_source\n",
    "\n",
    "# Estimate Average Treatment Effect (ATE)\n",
    "ate_result_doubleml = dml_ate_source(causal_data, n_folds=4)"
   ],
   "id": "9feee71ab51361fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Real ATE = 0.8\")\n",
    "print(f\"Estimated with Causalis = {ate_result_causalis.get('coefficient')} in {ate_result_causalis.get('confidence_interval')}\")\n",
    "print(f\"Estimated with DoubleML = {ate_result_doubleml.get('coefficient')} in {ate_result_doubleml.get('confidence_interval')}\")"
   ],
   "id": "419f242484901942"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ATTE",
   "id": "2517195764cb359"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from causalis.scenarios.unconfoundedness.atte import dml_atte\n",
    "\n",
    "# Estimate Average Treatment Effect on Treatment (ATTE)\n",
    "atte_result = dml_atte(causal_data, n_folds=4, normalize_ipw=False, store_diagnostic_data=False, random_state=123)"
   ],
   "id": "389e222e0fd112a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from causalis.scenarios.unconfoundedness.atte import dml_atte_source\n",
    "\n",
    "# Estimate Average Treatment Effect (ATE)\n",
    "ate_result_doubleml = dml_atte_source(causal_data, n_folds=4)"
   ],
   "id": "989214cdd0b2fb4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Real ATTE = 0.8\")\n",
    "print(f\"Estimated with Causalis = {atte_result.get('coefficient')} in {atte_result.get('confidence_interval')}\")\n",
    "print(f\"Estimated with DoubleML = {ate_result_doubleml.get('coefficient')} in {ate_result_doubleml.get('confidence_interval')}\")"
   ],
   "id": "e0b0d6ce3bf9d263"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "As we see estimates with Causalis are very close to the DoubleML. Nuance functions were out of box catboost model"
   ],
   "id": "fe1e711f8b2a8ab3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
