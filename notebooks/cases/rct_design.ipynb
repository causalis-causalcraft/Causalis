{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "\n",
    "import uuid\n",
    "import hashlib\n",
    "from typing import Dict, Optional\n",
    "import pandas as pd\n",
    "\n",
    "# --- Core AB assignment ---\n",
    "\n",
    "def _validate_variants(variants: Dict[str, float]) -> None:\n",
    "    \"\"\"Validate variant weights without normalization.\"\"\"\n",
    "    if not variants:\n",
    "        raise ValueError(\"Variants dictionary cannot be empty\")\n",
    "\n",
    "    total = 0.0\n",
    "    for name, weight in variants.items():\n",
    "        if weight < 0:\n",
    "            raise ValueError(f\"Variant '{name}' has negative weight: {weight}\")\n",
    "        total += weight\n",
    "\n",
    "    if total <= 0:\n",
    "        raise ValueError(\"Sum of variant weights must be > 0\")\n",
    "\n",
    "    if total > 1.0:\n",
    "        raise ValueError(f\"Sum of variant weights ({total}) exceeds 1.0\")\n",
    "\n",
    "\n",
    "def _hash_to_unit_interval(key: str) -> float:\n",
    "    \"\"\"Hash a key to a float in [0, 1).\"\"\"\n",
    "    h = hashlib.sha256(key.encode(\"utf-8\")).hexdigest()\n",
    "    n = int(h[:15], 16)\n",
    "    return n / (16 ** 15)\n",
    "\n",
    "\n",
    "def assign_variant(\n",
    "    entity_id: str,\n",
    "    experiment_id: str,\n",
    "    variants: Dict[str, float],\n",
    "    *,\n",
    "    salt: str = \"global_ab_salt\",\n",
    "    layer_id: str = \"default\",\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Assign a variant to an entity based on deterministic hashing.\n",
    "\n",
    "    Returns the variant name if the entity falls within experiment coverage,\n",
    "    or None if the entity is not in the experiment.\n",
    "    \"\"\"\n",
    "    _validate_variants(variants)\n",
    "\n",
    "    key = f\"{salt}|{layer_id}|{experiment_id}|{entity_id}\"\n",
    "    u = _hash_to_unit_interval(key)\n",
    "\n",
    "    cumulative = 0.0\n",
    "    for name, weight in sorted(variants.items()):\n",
    "        if weight == 0:\n",
    "            continue\n",
    "        cumulative += weight\n",
    "        if u < cumulative:\n",
    "            return name\n",
    "\n",
    "    return None  # Not in experiment\n",
    "\n",
    "\n",
    "# --- DataFrame in -> DataFrame out ---\n",
    "\n",
    "def assign_variants_df(\n",
    "    df: pd.DataFrame,\n",
    "    id_col: str,\n",
    "    experiment_id: str,\n",
    "    variants: Dict[str, float],\n",
    "    *,\n",
    "    salt: str = \"global_ab_salt\",\n",
    "    layer_id: str = \"default\",\n",
    "    variant_col: str = \"variant\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Deterministically assign variants for each row in df based on id_col.\n",
    "\n",
    "    Returns a copy of df with an extra column `variant_col`.\n",
    "    Entities outside experiment coverage will have None in the variant column.\n",
    "    \"\"\"\n",
    "    if id_col not in df.columns:\n",
    "        raise ValueError(f\"id_col '{id_col}' not found in DataFrame\")\n",
    "\n",
    "    _validate_variants(variants)\n",
    "\n",
    "    def _row_assign(entity_id: str) -> Optional[str]:\n",
    "        key = f\"{salt}|{layer_id}|{experiment_id}|{entity_id}\"\n",
    "        u = _hash_to_unit_interval(key)\n",
    "\n",
    "        cumulative = 0.0\n",
    "        for name, weight in sorted(variants.items()):\n",
    "            if weight == 0:\n",
    "                continue\n",
    "            cumulative += weight\n",
    "            if u < cumulative:\n",
    "                return name\n",
    "\n",
    "        return None  # Not in experiment\n",
    "\n",
    "    out = df.copy()\n",
    "    out[variant_col] = df[id_col].astype(str).map(_row_assign)\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "demo = pd.DataFrame({\n",
    "    \"user_id\": [str(uuid.uuid4()) for _ in range(100)]\n",
    "})\n",
    "\n",
    "variants = {\"control\": 0.2, \"treatment\": 0.2}\n",
    "assigned = assign_variants_df(\n",
    "    demo,\n",
    "    id_col=\"user_id\",\n",
    "    experiment_id=\"exp_signup_button_color_v1\",\n",
    "    salt = \"global_ab_salt\",\n",
    "    variants=variants,\n",
    "    layer_id=\"default\",\n",
    "    variant_col=\"treatment\"\n",
    ")\n",
    "\n",
    "print(assigned.head())\n",
    "print(assigned[\"treatment\"].value_counts())\n"
   ],
   "id": "abc60015f83bc284",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Because your hash key is your “random universe,” and those three fields control *which* universe you’re in.\n",
    "\n",
    "You effectively hash:\n",
    "\n",
    "```text\n",
    "key = salt | layer_id | experiment_id | entity_id\n",
    "```\n",
    "\n",
    "Each piece solves a different problem.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. `experiment_id`: isolate experiments + support reruns\n",
    "\n",
    "Why include it?\n",
    "\n",
    "* **Independence between experiments.**\n",
    "  If you *didn’t* use `experiment_id`, the same user would always map to the same bucket across *all* experiments. That means:\n",
    "\n",
    "  * If user is “treatment” once, they’d be “treatment” everywhere → correlated assignments → biased results when you compare across tests.\n",
    "* **Stable within a single experiment.**\n",
    "  Given fixed `experiment_id`, a user keeps their bucket forever (idempotent).\n",
    "* **Versioning / reruns.**\n",
    "  Want a fresh randomization? Use `experiment_id=\"exp_checkout_v2\"` and you get a new random split without touching code.\n",
    "\n",
    "Rule of thumb: **new logical test or new randomization → new `experiment_id`.**\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `salt`: prevent gaming + cross-system collisions\n",
    "\n",
    "Why include it?\n",
    "\n",
    "* **Security / anti-gaming.**\n",
    "  Without a secret salt, savvy users/devs could guess:\n",
    "\n",
    "  * “If my user_id ends with X I get treatment, so I’ll farm accounts with that pattern.”\n",
    "* **Isolation from other uses of hashing.**\n",
    "  You might use SHA256 elsewhere; `salt` ensures the A/B assignment space is unique.\n",
    "* **Safe to share IDs.**\n",
    "  You can expose experiment names & variant labels in logs/BI without making it trivial to reverse or shape assignments.\n",
    "\n",
    "Rule of thumb: **keep `salt` server-side, same across platform; rotate only with a migration plan** (rotation changes assignments).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `layer_id`: control mutual exclusivity & traffic layers\n",
    "\n",
    "Think of `layer_id` as “which slot of the product UI this experiment lives in”.\n",
    "\n",
    "Why include it?\n",
    "\n",
    "* **Mutual exclusivity.**\n",
    "  Suppose you have many experiments on the home screen. You don’t want one user in 5 conflicting treatments.\n",
    "\n",
    "  * Put them in the same `layer_id=\"home_feed\"`, then use the same hash stream to decide **which single experiment** (or variant) a user sees.\n",
    "* **Independent surfaces.**\n",
    "  Experiments on unrelated areas (e.g. `\"search_page\"` vs `\"pricing_page\"`) should not compete:\n",
    "\n",
    "  * Different `layer_id` → independent assignments, even for same user.\n",
    "\n",
    "Rule of thumb:\n",
    "\n",
    "* Use **one layer per logical surface or exclusivity group**.\n",
    "* Default `\"default\"` is fine if you don’t yet run overlapping tests.\n",
    "\n",
    "---\n",
    "\n",
    "So:\n",
    "\n",
    "* `experiment_id` → “which experiment”.\n",
    "* `layer_id` → “which exclusivity sandbox”.\n",
    "* `salt` → “make the whole thing safe & non-predictable”.\n",
    "\n",
    "Together they give you: deterministic, debuggable, replayable, non-correlated, and non-gameable assignments — i.e. what modern A/B platforms try to guarantee.\n"
   ],
   "id": "1d3948576b91482b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from causalis.scenarios.rct.rct_design import assign_variants_df\n",
    "import pandas as pd\n",
    "import uuid"
   ],
   "id": "7533b6ff50a64cdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "demo = pd.DataFrame({\n",
    "    \"user_id\": [str(uuid.uuid4()) for _ in range(100)]\n",
    "})\n",
    "\n",
    "variants = {\"control\": 0.2, \"treatment\": 0.2}\n",
    "assigned = assign_variants_df(\n",
    "    demo,\n",
    "    id_col=\"user_id\",\n",
    "    experiment_id=\"exp_signup_button_color_v1\",\n",
    "    salt = \"global_ab_salt\",\n",
    "    variants=variants,\n",
    "    layer_id=\"default\",\n",
    "    variant_col=\"treatment\"\n",
    ")\n",
    "\n",
    "print(assigned.head())\n",
    "print(assigned[\"treatment\"].value_counts())\n"
   ],
   "id": "35be4ee452210a03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8cbb3eb5593de305",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How layer_id is intended to be used in a full platform:\n",
    "\n",
    "You define a “layer router”:\n",
    "\n",
    "Example: layer_id=\"home_feed\" decides which one of several experiments (or none) a user enters.\n",
    "\n",
    "Those experiments share the same layer to enforce mutual exclusivity."
   ],
   "id": "8f86a11f899242ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SRM",
   "id": "2298cadcfedc61f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from __future__ import annotations\n",
    "#\n",
    "# from dataclasses import dataclass\n",
    "# from typing import Dict, Hashable, Iterable, Union\n",
    "#\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "#\n",
    "# try:\n",
    "#     from scipy.stats import chi2\n",
    "# except ImportError as e:  # pragma: no cover\n",
    "#     chi2 = None\n",
    "#     _scipy_import_error = e\n",
    "# else:\n",
    "#     _scipy_import_error = None\n",
    "#\n",
    "#\n",
    "# Number = Union[int, float]\n",
    "#\n",
    "#\n",
    "# @dataclass\n",
    "# class SRMResult:\n",
    "#     \"\"\"\n",
    "#     Result of a Sample Ratio Mismatch (SRM) check.\n",
    "#     \"\"\"\n",
    "#     chi2: float\n",
    "#     df: int\n",
    "#     p_value: float\n",
    "#     expected: Dict[Hashable, float]\n",
    "#     observed: Dict[Hashable, int]\n",
    "#     alpha: float\n",
    "#     is_srm: bool\n",
    "#     warning: str | None = None\n",
    "#\n",
    "#     def __repr__(self) -> str:\n",
    "#         status = \"SRM DETECTED\" if self.is_srm else \"no SRM\"\n",
    "#         return (\n",
    "#             f\"SRMResult(status={status}, p_value={self.p_value:.3e}, \"\n",
    "#             f\"chi2={self.chi2:.4f}, df={self.df})\"\n",
    "#         )\n",
    "#\n",
    "#\n",
    "# def check_srm(\n",
    "#     assignments: Union[Iterable[Hashable], pd.Series],\n",
    "#     target_allocation: Dict[Hashable, Number],\n",
    "#     alpha: float = 1e-3,\n",
    "#     min_expected: float = 5.0,\n",
    "#     strict_variants: bool = True,\n",
    "# ) -> SRMResult:\n",
    "#     \"\"\"\n",
    "#     Check Sample Ratio Mismatch (SRM) for an RCT via chi-square goodness-of-fit test.\n",
    "#\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     assignments:\n",
    "#         Iterable of assigned variant labels for each unit (user_id, session_id, etc.).\n",
    "#         E.g. Series of [\"control\", \"treatment\", ...].\n",
    "#\n",
    "#     target_allocation:\n",
    "#         Mapping {variant: p} describing intended allocation as PROBABILITIES.\n",
    "#         - Each p must be > 0.\n",
    "#         - Sum of all p must be 1.0 (within numerical tolerance).\n",
    "#\n",
    "#         Examples:\n",
    "#             {\"control\": 0.5, \"treatment\": 0.5}\n",
    "#             {\"A\": 0.2, \"B\": 0.3, \"C\": 0.5}\n",
    "#\n",
    "#     alpha:\n",
    "#         Significance level. Use strict values like 1e-3 or 1e-4 in production.\n",
    "#\n",
    "#     min_expected:\n",
    "#         If any expected count < min_expected, a warning is attached.\n",
    "#\n",
    "#     strict_variants:\n",
    "#         - True: fail if observed variants differ from target keys.\n",
    "#         - False: drop unknown variants and test only on declared ones.\n",
    "#\n",
    "#     Returns\n",
    "#     -------\n",
    "#     SRMResult\n",
    "#     \"\"\"\n",
    "#     # --- Prepare data\n",
    "#     s = pd.Series(list(assignments)).dropna()\n",
    "#     if s.empty:\n",
    "#         raise ValueError(\"No assignments provided for SRM check.\")\n",
    "#\n",
    "#     if not target_allocation:\n",
    "#         raise ValueError(\"target_allocation cannot be empty.\")\n",
    "#\n",
    "#     # Validate probabilities\n",
    "#     probs = np.array(list(target_allocation.values()), dtype=float)\n",
    "#\n",
    "#     if (probs <= 0).any():\n",
    "#         raise ValueError(\"All target allocation probabilities must be > 0.\")\n",
    "#\n",
    "#     total = float(probs.sum())\n",
    "#     if not np.isclose(total, 1.0, rtol=1e-6, atol=1e-8):\n",
    "#         raise ValueError(\n",
    "#             f\"target_allocation probabilities must sum to 1.0, got {total:.6f}.\"\n",
    "#         )\n",
    "#\n",
    "#     variants = list(target_allocation.keys())\n",
    "#     target_map = dict(zip(variants, probs))\n",
    "#\n",
    "#     # Observed counts\n",
    "#     if strict_variants:\n",
    "#         unexpected = set(s.unique()) - set(variants)\n",
    "#         if unexpected:\n",
    "#             raise ValueError(\n",
    "#                 f\"Found assignments to variants not in target_allocation: {unexpected}\"\n",
    "#             )\n",
    "#\n",
    "#     if not strict_variants:\n",
    "#         s = s[s.isin(variants)]\n",
    "#         if s.empty:\n",
    "#             raise ValueError(\n",
    "#                 \"After filtering to target variants, no assignments remain.\"\n",
    "#             )\n",
    "#\n",
    "#     observed_counts = s.value_counts().reindex(variants).fillna(0).astype(int)\n",
    "#     n = int(observed_counts.sum())\n",
    "#     if n == 0:\n",
    "#         raise ValueError(\"Total sample size is zero after preprocessing.\")\n",
    "#\n",
    "#     # Expected counts from probabilities * n\n",
    "#     expected_counts = np.array(\n",
    "#         [target_map[v] * n for v in variants],\n",
    "#         dtype=float\n",
    "#     )\n",
    "#\n",
    "#     # Chi-square statistic\n",
    "#     with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "#         chi2_components = (observed_counts.values - expected_counts) ** 2 / expected_counts\n",
    "#     chi2_components = np.nan_to_num(chi2_components, nan=0.0, posinf=0.0)\n",
    "#     chi2_stat = float(chi2_components.sum())\n",
    "#\n",
    "#     # Degrees of freedom\n",
    "#     k = (expected_counts > 0).sum()\n",
    "#     df = max(k - 1, 1)\n",
    "#\n",
    "#     if chi2 is None:\n",
    "#         raise ImportError(\n",
    "#             \"scipy is required for p-value computation in check_srm(). \"\n",
    "#             f\"Original error: {_scipy_import_error}\"\n",
    "#         )\n",
    "#\n",
    "#     p_value = float(chi2.sf(chi2_stat, df))\n",
    "#\n",
    "#     warning = None\n",
    "#     if (expected_counts < min_expected).any():\n",
    "#         warning = (\n",
    "#             f\"Some expected cell counts are < {min_expected:.1f}. \"\n",
    "#             \"Chi-square approximation may be unreliable; \"\n",
    "#             \"consider exact or simulation-based tests.\"\n",
    "#         )\n",
    "#\n",
    "#     is_srm = p_value < alpha\n",
    "#\n",
    "#     return SRMResult(\n",
    "#         chi2=chi2_stat,\n",
    "#         df=df,\n",
    "#         p_value=p_value,\n",
    "#         expected={v: float(e) for v, e in zip(variants, expected_counts)},\n",
    "#         observed={v: int(o) for v, o in zip(variants, observed_counts)},\n",
    "#         alpha=alpha,\n",
    "#         is_srm=is_srm,\n",
    "#         warning=warning,\n",
    "#     )\n"
   ],
   "id": "15c6c1d67dba9744",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from causalis.scenarios.rct import check_srm\n",
    "import pandas as pd\n",
    "\n",
    "target = {\"control\": 0.5, \"treatment\": 0.5}\n",
    "\n",
    "# Realized assignments: 1200 vs 800 instead of 1000 vs 1000\n",
    "df_bad = pd.DataFrame({\n",
    "    \"user_id\": range(2000),\n",
    "    \"variant\": [\"control\"] * 1200 + [\"treatment\"] * 800\n",
    "})\n",
    "\n",
    "res_bad = check_srm(\n",
    "    assignments=df_bad[\"variant\"],\n",
    "    target_allocation=target,\n",
    "    alpha=1e-3\n",
    ")\n",
    "\n",
    "print(res_bad)\n",
    "print(\"Observed:\", res_bad.observed)\n",
    "print(\"Expected:\", res_bad.expected)\n",
    "print(\"is_srm:\", res_bad.is_srm)\n",
    "print(\"warning:\", res_bad.warning)\n"
   ],
   "id": "984293a96c819cdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T09:05:28.173140Z",
     "start_time": "2025-11-08T09:05:27.372007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "target = {\"control\": 0.5, \"treatment\": 0.5}\n",
    "\n",
    "# Realized assignments: 1200 vs 800 instead of 1000 vs 1000\n",
    "df_bad = pd.DataFrame({\n",
    "    \"user_id\": range(2000),\n",
    "    \"variant\": [\"control\"] * 1200 + [\"treatment\"] * 800\n",
    "})\n",
    "\n",
    "res_bad = check_srm(\n",
    "    assignments=df_bad[\"variant\"],\n",
    "    target_allocation=target,\n",
    "    alpha=1e-3\n",
    ")\n",
    "\n",
    "print(res_bad)\n",
    "print(\"Observed:\", res_bad.observed)\n",
    "print(\"Expected:\", res_bad.expected)\n",
    "print(\"is_srm:\", res_bad.is_srm)\n",
    "print(\"warning:\", res_bad.warning)\n"
   ],
   "id": "895fb7a63d0b124b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T09:05:28.644679Z",
     "start_time": "2025-11-08T09:05:28.634998Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3f83bafa3ae90e35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRMResult(status=SRM DETECTED, p_value=3.744e-19, chi2=80.0000, df=1)\n",
      "Observed: {'control': 1200, 'treatment': 800}\n",
      "Expected: {'control': 1000.0, 'treatment': 1000.0}\n",
      "is_srm: True\n",
      "warning: None\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
